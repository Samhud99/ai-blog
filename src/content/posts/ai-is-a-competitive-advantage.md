---
title: "AI is a Competitive Advantage"
excerpt: "Why some moats are eroding while others remain. If the only thing protecting a moat was that intelligence was scarce and expensive, AI is removing that protection."
date: "2026-02-15"
published: true
---

# AI is a Competitive Advantage

*Written by Sam Hudson, with research and editing assistance from AI*

In my last article, I argued that code complexity is becoming a less reliable moat. AI has reduced the cost of building software, and that gives businesses and consumers more options than they've had before. Replacing a vendor, building it yourself, or negotiating a better deal.

This article will aim to focus more on the "why." Why are some moats eroding while others remain?

I think the answer comes down to what's actually protecting them. If the only thing protecting a moat was that intelligence was scarce and expensive, AI is removing that protection. If it's protected by something else, it's probably more durable.

## Limiting Factors of Intelligence

Dario Amodei (CEO of Anthropic) has a framework that I think helps make sense of this. In *Machines of Loving Grace* and *The Adolescence of Technology*, he argues that intelligence is only one input into progress. Even as AI makes intelligence more abundant and accessible, five other factors remain as bottlenecks:

1. **Speed of the outside world.** Physical things take time. Manufacturing, experiments, institutional change. You can't think your way past this.
2. **Need for data.** If the data doesn't exist, more intelligence doesn't help. You have to go collect it, and that takes time too.
3. **Intrinsic complexity.** Some systems are chaotic. Human behaviour, brand perception, social dynamics. Intelligence only gets you marginally better predictions in these systems.
4. **Constraints from humans.** Regulation, law, habits, willingness to change. Plenty of things that work technically are held back by human factors. Amodei cites nuclear power and supersonic flight as examples.
5. **Physical laws.** Hard ceilings. These don't move.

These five factors are not about intelligence. They're about everything else. As AI reduces the intelligence bottleneck, these remain regardless of how capable the models get.

This suggests a useful way to think about any competitive advantage: what is actually protecting it? If the main thing protecting it was that intelligence was scarce and expensive (it was hard to build, it required rare talent, it took clever engineering), that protection may weaken over time. If it's protected by one of Amodei's five limiting factors, it's probably more durable.

Coding is where this shows up first, because it's one of the few valuable economic activities that isn't really constrained by any of the other five bottlenecks. No physical processes to wait for, no regulatory gates, no dependence on scarce real-world data. Nearly pure intelligence work. Which is probably why AI has improved at it so fast, and why software is worth looking at as an early indicator for other industries.

## Competitive Advantage

Hamilton Helmer's *7 Powers* is the standard framework for durable competitive advantage. Scale economies, network economies, counter-positioning, switching costs, branding, cornered resource, and process power.

When you hold these up against Amodei's limiting factors, a pattern shows up. The barriers that depend primarily on intelligence scarcity (expensive R&D, complex integrations, large engineering teams) are the ones under most pressure. AI reduces the cost of R&D, writes migration scripts in hours, and increases leverage per engineer to the point where headcount matters less.

The barriers protected by the other five factors look more durable. Brand trust is protected by intrinsic complexity. Regulatory approvals, contractual lock-in, and organisational habits are all protected by constraints from humans. Proprietary data is protected by the need for data and speed of the outside world. You can't synthesise ten years of real customer behaviour, and SOC 2 compliance takes years regardless of how capable the AI is.

Counter-positioning is an interesting exception. It may actually be strengthened by AI. New entrants can build competitive alternatives faster than ever. But the incumbent's barriers to responding (revenue considerations, board expectations, organisational identity) are all constraints from humans. The offence gets faster while the defence stays roughly the same speed.

The pattern that starts to emerge isn't really about individual powers holding up or not. It's about who is positioned to take advantage of the shifts across all of them.

And that might be the more interesting question. Not "which powers hold up?" but "who is best at using AI to take advantage of the changes happening across all of them?"

A company that can use AI to move faster, build alternatives quickly, accumulate data advantages, and deliver quality at speed isn't relying on any single power. It's working across the shifts between them.

## Implications Beyond Silicon Valley

If organisational AI capability does turn out to be a meaningful advantage, it's worth noting that it doesn't belong exclusively to Silicon Valley firms or startups.

Any organisation that develops strong AI practices could start building its own tools where it makes sense. Not replacing every SaaS subscription overnight. But having the option to, in specific areas, and knowing that the option exists.

That's part of what makes option B (build it yourself) from Part 1 worth considering. Even if a company never fully exercises that option, being able to changes the conversation.

Enterprise software is deeply embedded, and there are good reasons (reliability, security, support, integration depth) why organisations pay for established products. None of that is going away. But the range of options available to buyers is gradually widening.

## Looking Ahead

In the long run, whether it's a new entrant, an incumbent, a supplier, or a customer, the companies that treat AI as an opportunity will outperform those that treat it as a threat to manage.

By "treat it as an opportunity," I don't just mean adopting AI tools. I mean understanding how AI changes the competitive landscape around your business, and being agile enough to respond or disrupt when it arrives. Right now, software development is the clearest example. But this dynamic will likely reach other industries as AI capability improves, just at different speeds depending on how much Amodei's limiting factors constrain them.

Every situation is different, but Helmer's *7 Powers* provides a useful starting point for thinking through which of your moats are protected by something durable, and which ones were only ever protected by the scarcity of intelligence.

For SaaS companies, that question is already urgent. Understanding which of your moats actually hold up, and shifting toward the ones that do, is not something that can wait. For companies in other industries, there's more time, but the pattern is the same one we've seen with every major technology shift. The organisations that embraced the internet early didn't just survive the transition, they shaped it. AI is likely no different.

---

## Sources

1. Dario Amodei, *Machines of Loving Grace* (October 2024) and *The Adolescence of Technology* (January 2026)
2. Hamilton Helmer, *7 Powers: The Foundations of Business Strategy*

## More Interesting Reading

- Ben Thompson, *Microsoft and Software Survival* (February 2026) — on AI-written code and the long-term economics of software companies
- Janelle Teng Wade, *The SaaSacre of 2026* (February 2026) — a VC's breakdown of the AI-related fears driving the current software selloff
- a16z, *From Demos to Deals: Insights for Building in Enterprise AI* (July 2025) — on where moats actually form in enterprise AI
- Christoph Janz, *Some Learnings from Vibe Coding a Knowledge Hub in 13 Days* (January 2026) — a VC builds a 43,000 line system without writing code, and reflects on what it means for SaaS
- SaaStr, *The 2026 SaaS Crash: It's Not What You Think* (February 2026) — argues the crash is real but the "AI kills SaaS" narrative is mostly wrong
- Margin of Safety, *SaaSpocalypse, Vibe Coding, and the New Scarcity* (February 2026) — on accountability, maintenance, and the limits of vibe coding in enterprise
- Les Barclays, *Who captures the value when AI inference costs trend to zero?*

---

*The views and opinions expressed in this article are solely those of the author and do not represent, reflect, or constitute the official position of any organization, company, or entity with which the author is or has been affiliated. The content herein is provided for general informational purposes only.*
